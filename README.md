# Towards Addressing Anthropocentric Bias in Large Language Models

The widespread use of Large Language Models (LLMs), particularly among non-expert users, has raised ethical concerns about the propagation of harmful biases. While much research has addressed social biases, no work to date has examined anthropocentric bias in Natural Language Processing (NLP) technology. Anthropocentric language prioritizes human value, framing non-human animals, living entities, and natural elements solely by their utility to humans; a perspective that contributes to the ecological crisis. In this paper, we evaluate anthropocentric bias in OpenAI’s GPT-4o across various target entities, including sentient beings, non-sentient entities, and natural elements. Using prompts eliciting neutral, anthropocentric, and ecocentric perspectives, we analyze the model’s outputs and introduce a manually curated glossary of 382 anthropocentric terms as a resource for future ecocritical research. Our findings reveal a strong anthropocentric bias in the model's responses, underscoring the need to address human-centered language use in AI-generated text to promote ecological well-being.

# Code
We provide a Jupyter notebook that contains the code we used to prompt GPT-4o using OpenAI APIs (an API key is needed to send requests, see here how to obtain one: https://openai.com/api/) and to perform the pre-processing of the generated ouputs.

# LICENSE

The code and the data in this repository are licensed under the Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) license. This means you are free to share, copy, distribute, and transmit the work or to adapt it, provided you attribute it appropriately, and distribute any derivative works under a similar license.

For full license details, please refer to the LICENSE.txt file provided with the dataset.
